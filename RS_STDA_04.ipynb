{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTHSBvapofNt"
      },
      "source": [
        "# Research Skills: Spatiotemporal Data Analysis\n",
        "# Worksheet 4 - Fundamentals for Spatial Data Analysis\n",
        "\n",
        "Sharon Ong, Department of Cognitive Science and Artificial Intelligence â€“ Tilburg University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdZ6pu-4ofN-"
      },
      "source": [
        "You will be introduced to the concepts of (geo)spatial data, and more specifically to vector data.\n",
        "\n",
        "\n",
        "You will then learn how to represent such data in a GeoDataFrame using the GeoPandas library, and the basics to read, explore and visualize such data. And you will exercise all this with some datasets about the Netherlands.\n",
        "\n",
        "One of the key aspects of geospatial data is how they relate to each other in space. In this worksheet, you will learn the spatial relationships such as spatial weights, spatial lag.   \n",
        "\n",
        "Spatial Point Process Analysis\n",
        "1. Visualization of Spatial Point Processes\n",
        "2. Centrography\n",
        "3. Density functions: Kernel Density Functions, Quadrant Density Functions\n",
        "4. Average Nearest Neighbour Distance\n",
        "5. Ripley's K Functions\n",
        "\n",
        "Spatial Lattice Data Analysis\n",
        "\n",
        "6. Creating a GeoDataFrame\n",
        "7. Handling maps (lattice data) with Python\n",
        "8. Displaying vector data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Setup\n",
        "Please specify in the next cell if you are working from Google Colab or from your own computer. Also indicate if you already have the necessary libraries installed."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ko6eXwqBH0TI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "COLAB = True\n",
        "LIBRARIES_INSTALLED = False"
      ],
      "metadata": {
        "id": "z6VYt9HUH0TI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh5cr6H6rHHQ"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Load the contents of the directory\n",
        "    !ls\n",
        "    # Change your working directory to the folder where you stored your files, e.g.\n",
        "    %cd /content/drive/My Drive/Colab Notebooks/STDA\n",
        "\n",
        "if not LIBRARIES_INSTALLED:\n",
        "    !pip install seaborn\n",
        "    !pip install contextily\n",
        "    !pip install pointpats\n",
        "    !pip install mapclassify\n",
        "\n",
        "from os.path import join\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import contextily as ctx\n",
        "import pointpats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYObMxaRtlCb",
        "tags": []
      },
      "source": [
        "# 1. Visualization of Spatial Point Processes\n",
        "\n",
        "An example of spatial point process are geo-tagged photos. Geo-tagged photos uploaded to online services is creating new ways for researchers to study and understand cities. Where do people take pictures? When are those pictures taken? Why do certain places attract many more photographers than others? We will use the Tokyo Photographs Dataset for this exercise. This dataset contains geo-tagged Flickr photos from Tokyo. We will treat the phenomena represented in the data as events: photos could be taken of any place in Tokyo, but only certain locations are captured."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHpRrnXYyOPh"
      },
      "source": [
        "The following code loads the dataset. The dataset contains the following information about the sample of 10,000 photographs: the ID of the user who took the photo; the location expressed as latitude and longitude columns; a transformed version of those coordinates expressed in Pseudo Mercator; the timestamp when the photo was taken; and the URL where the picture they refer to is stored online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8LfVV06yNZb"
      },
      "outputs": [],
      "source": [
        "db = pd.read_csv(join('data', 'tokyo_clean.csv'))\n",
        "\n",
        "# To find out more information about the dataset.\n",
        "db.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd1GVtRlykWy"
      },
      "source": [
        "Plot the longitude and latitude on a scatter plot with a dot size (`s`) of 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A66lZ-ui_8g2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5-0R8mpADck"
      },
      "source": [
        "The code below creates a scatter plot the seaborn package and displays the map in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgDRPzgaAf7f"
      },
      "outputs": [],
      "source": [
        "# Create scatter plot with histograms on axes\n",
        "joint_axes = sns.jointplot(x='longitude', y='latitude', data=db, s=0.75)\n",
        "\n",
        "# Add basemap\n",
        "ctx.add_basemap(joint_axes.ax_joint, crs=\"EPSG:4326\", source=ctx.providers.CartoDB.PositronNoLabels)\n",
        "\n",
        "# Remove axes\n",
        "joint_axes.ax_joint.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8CVhY0WynSB"
      },
      "source": [
        "# 2. Centrography\n",
        "Centrography is the analysis of centrality (general location and dispersion) in a point pattern. These measures are useful because they allow us to summarize spatial distributions in smaller sets of information (e.g. a single point). The following code computes the mean and median center of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VfJbGuRyr1s"
      },
      "outputs": [],
      "source": [
        "mean_center = pointpats.centrography.mean_center(db[['x', 'y']])\n",
        "med_center = pointpats.centrography.euclidean_median(db[['x', 'y']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8mPkqqq-XNj"
      },
      "source": [
        "The following code plots the mean and median points and marginal lines.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tvfYqGnMyc"
      },
      "outputs": [],
      "source": [
        "# Generate scatter plot\n",
        "joint_axes = sns.jointplot(x='x', y='y', data=db, s=0.75)\n",
        "\n",
        "# Add mean point and marginal lines\n",
        "joint_axes.ax_joint.scatter(*mean_center, color='red', marker='x', s=50, label='Mean Center')\n",
        "joint_axes.ax_marg_x.axvline(mean_center[0], color='red')\n",
        "joint_axes.ax_marg_y.axhline(mean_center[1], color='red')\n",
        "\n",
        "# Add median point and marginal lines\n",
        "joint_axes.ax_joint.scatter(*med_center, color='limegreen', marker='o', s=50, label='Median Center')\n",
        "joint_axes.ax_marg_x.axvline(med_center[0], color='limegreen')\n",
        "joint_axes.ax_marg_y.axhline(med_center[1], color='limegreen')\n",
        "\n",
        "# Legend\n",
        "joint_axes.ax_joint.legend()\n",
        "\n",
        "# Add basemap\n",
        "ctx.add_basemap(joint_axes.ax_joint, source=ctx.providers.CartoDB.Voyager)\n",
        "\n",
        "# Remove axes\n",
        "joint_axes.ax_joint.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJi8Pqzhnew_"
      },
      "source": [
        "A measure of dispersion that is common in centrography is the *standard distance*. This measure provides the average distance away from the center of the point cloud (such as measured by the center of mass). To compute the standard distance, you can use the `std_distance` function in `pointpats.centrography`. Compute the *standard distance* of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-PYrgxWnM5N",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmsRcWUHsUH0"
      },
      "source": [
        "Another helpful visualization is the *standard deviational ellipse*, or *standard ellipse* which shows the dispersion and orientation of the dataset. The following code first computes the axes, and rotation of the ellipse. Next, the code shows you how to display the ellipse on the map.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpaFbnSl-Xfn"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "major, minor, rotation = pointpats.centrography.ellipse(db[['x','y']])\n",
        "\n",
        "# Set up figure and axis\n",
        "fig, ax = plt.subplots(figsize=(9, 9))\n",
        "\n",
        "# Plot photograph points\n",
        "ax.scatter(db['x'], db['y'], s=0.75)\n",
        "ax.scatter(*mean_center, color='red', marker='x', label='Mean Center')\n",
        "ax.scatter(*med_center, color='limegreen', marker='o', label='Median Center')\n",
        "\n",
        "# Construct the standard ellipse using matplotlib\n",
        "ellipse = Ellipse(xy=mean_center, # center the ellipse on our mean center\n",
        "                  width=major*2, # centrography.ellipse only gives half the axis\n",
        "                  height=minor*2,\n",
        "                  angle=np.rad2deg(rotation), # Angles for this are in degrees, not radians\n",
        "                  facecolor='none', # Aesthetics\n",
        "                  edgecolor='red',\n",
        "                  linestyle='--',\n",
        "                  label='Std. Ellipse')\n",
        "ax.add_patch(ellipse)\n",
        "ax.legend()\n",
        "\n",
        "# Add basemap\n",
        "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
        "\n",
        "# Remove axes\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code block below:\n",
        "\n",
        "1. Find the users that have posted the most pictures in Tokyo using pandas' `.mode()` method\n",
        "2. Create a dataframe that only contains the rows from one of these users\n",
        "3. Find the mean center and euclidean mean of this user\n",
        "4. Plot the user's photo locations as a scatter plot, the centroids, and the std. ellipse"
      ],
      "metadata": {
        "collapsed": false,
        "id": "exfHsyMjH0TN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ],
      "metadata": {
        "id": "YVN8zD-KH0TN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8OFF5fU-frD",
        "tags": []
      },
      "source": [
        "# 3 Density Plots\n",
        "When too many photos are concentrated in some areas of, plotting opaque dots on top of one another can make it hard to discern any pattern and explore its nature.\n",
        "\n",
        "## 3.1 Kernel Density Plots\n",
        "Kernel density estimation (KDE): an empirical approximation of the probability density function. Instead of overlaying a grid of squares and count how many points fall within each, we can use a Kernel density estimation (KDE) to lay kernel functions over a grid of points with different weight based on the distance. These counts are then aggregated to generate a global surface with probability. The most common kernel function is the Gaussian one, which applies a normal distribution to weight points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNcSjH9BxVHF",
        "tags": []
      },
      "source": [
        "The code belows generates a number of random points; where there is no clusteirng or dispersion effect. In point pattern analysis, this is known as a *Poisson point process*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur59T9DltlU3"
      },
      "outputs": [],
      "source": [
        "user = db.loc[db.user_id == '95795770@N00']\n",
        "coordinates = user[['longitude','latitude']].values\n",
        "points = pointpats.random.poisson(coordinates, size=len(coordinates))\n",
        "\n",
        "plt.scatter(points[:, 0], points[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNb8Yj5jimyq"
      },
      "source": [
        "The code below creates a kernel density plot with a shading of 50 gradients and a transpancy of 55%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt0l7zckn2rA"
      },
      "outputs": [],
      "source": [
        "sns.kdeplot(x=points[:, 0], y=points[:, 1], n_levels=50, fill=True, alpha=0.55, cmap='viridis_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3INwQZg5uBNG"
      },
      "source": [
        "Display the Kernel Density Plot for the Tokyo Dataset with the map in the background. Set `n_levels` to 50 and `cmap` to 'viridis_r'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdtRdqOP_lei"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the Kernel Density Plot for the user with the most uploaded photos, use the same settings as the previous plot, but set `cmap` to 'jet_r'."
      ],
      "metadata": {
        "collapsed": false,
        "id": "atvqS5KuH0TP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCmu-7FNgNSE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLjvNv1_0lT"
      },
      "source": [
        "## 3.2 Quadrant Density Plot\n",
        "\n",
        "Quadrant statistics examines the spatial distribution of points in an area by counting the observations that fall within a given cell. A quadrant statistics examines the *evenness* of the distribution over cells using a $\\chi^2$ statistical test common in the analysis of contingency tables.\n",
        "\n",
        "The code below plots applies quadrant statistics on the previously generated random spatial process and plots the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDh1rwtAj9XH"
      },
      "outputs": [],
      "source": [
        "qstat = pointpats.QStatistic(points)\n",
        "qstat.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rMJYVnFwXhX"
      },
      "source": [
        "The code belows displays the p value of the $\\chi^2$, which shows that p value is large and not significant.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-b1WYWY_0ZZ"
      },
      "outputs": [],
      "source": [
        "qstat.chi2_pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLOC5llLwg6I"
      },
      "source": [
        "Compute the quadrant statistics on the data from the `coordinates` variable. Display the Quadrant plot and compute the p value of the $\\chi^2$.\n",
        "Is the p value significant?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zgfnfLJA-9S"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAIyP-quwuw2"
      },
      "source": [
        "# 4. Average Nearest Neighbour\n",
        "The following code compute the nearest neighbour for the random point process and draws an arrow from each point to its nearest neighbour.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa3zRf-I0kIR"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4), sharex=True, sharey=True, layout='constrained')\n",
        "\n",
        "axs[0].scatter(*points.T, color='red', marker='.')\n",
        "axs[1].scatter(*points.T, color='red', zorder=100, marker='.', label='Point')\n",
        "\n",
        "pp = pointpats.PointPattern(points)\n",
        "nn_ixs, nn_ds = pp.knn(1)\n",
        "\n",
        "first = True\n",
        "for coord, nn_ix, nn_d in zip(points, nn_ixs, nn_ds):\n",
        "    dx, dy = points[nn_ix].squeeze() - coord\n",
        "    if first:\n",
        "        first = False\n",
        "        arrow = axs[1].arrow(*coord, dx, dy, length_includes_head=True, facecolor='k', width=0.001, label='Nearest Neighbor of Point')\n",
        "    else:\n",
        "        arrow = axs[1].arrow(*coord, dx, dy, length_includes_head=True, facecolor='k', width=0.003, head_width=0.005)\n",
        "\n",
        "axs[0].set_axis_off()\n",
        "axs[1].set_axis_off()\n",
        "axs[1].legend(bbox_to_anchor=(0.7, -0.1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoepI1B16Gkp",
        "tags": []
      },
      "source": [
        "# 5. K(d) functions\n",
        "\n",
        "K(d) fucntions summarizes the density between points for all distances. It consists of dividing the mean of  sum of the number of points at different distance lags for each point by the entire area. The following code applies a K function on the random point process and plots it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G0Am_Fn5inj"
      },
      "outputs": [],
      "source": [
        "dist, k = pointpats.k(points)\n",
        "\n",
        "plt.plot(dist, k)\n",
        "plt.xlabel('Distance (km)')\n",
        "plt.ylabel('K')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whUgt-Vu-lbv"
      },
      "source": [
        "Compute the K function for the single user coordinates from the Tokyo dataset   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFGkXYMh58qB"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Rh4peLofOA"
      },
      "source": [
        "# 6. Creating a GeoDataFrame\n",
        "The following loads a csv file of some major cities in North Brabant and converts the dataset to a GeoDataFrame.  \n",
        "1. Inspect the first 5 rows of the cities dataframe and the  with the head() method. Do you see the columns with coordinates?\n",
        "2. Visualize the locations of the cities (you may use the `gdf.plot()` or matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr9X28eUofOC"
      },
      "outputs": [],
      "source": [
        "cities = pd.read_csv(join('data', 'nl_noord-brabant_main.csv'))\n",
        "print(cities.head())\n",
        "gdf = gpd.GeoDataFrame(cities, geometry=gpd.points_from_xy(cities.lng, cities.lat))\n",
        "\n",
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RWsaFvZofOE"
      },
      "source": [
        "# 7. Handling Choropleth maps with Python\n",
        "GeoDataFrames can be used to store simple geographical features, along with their non-spatial attribute. The GeoPandas library has functions to read, explore and visualize such data.  These geographical features include points (therefore addresses and locations), line strings (therefore streets, highways and boundaries), polygons (countries, provinces, tracts of land), and multi-part collections of these type. The following code loads a shapefile of all the municipalities in the Netherlands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaKD_ZRVofOE"
      },
      "outputs": [],
      "source": [
        "gemeenten = gpd.read_file(join('data', 'wijkbuurtkaart_2023_v1', 'gemeenten_2023_v1.shp'))\n",
        "\n",
        "# Display the shapes (e.g. polygons and multi-polygons) with a transparency of 0.5,\n",
        "# green face color and black edges\n",
        "ax = gemeenten.plot(figsize=(12, 12), alpha=0.5, facecolor='g', edgecolor='w')\n",
        "\n",
        "display(gemeenten.head())\n",
        "\n",
        "# Annotate the polygon with its index\n",
        "gemeenten['coords'] = gemeenten['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
        "\n",
        "display(gemeenten.head())\n",
        "\n",
        "gemeenten['coords'] = [coords[0] for coords in gemeenten['coords']]\n",
        "for idx, row in gemeenten.iterrows():\n",
        "    plt.annotate(idx, xy=row['coords'], horizontalalignment='center')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzRQutLRofOF"
      },
      "source": [
        "If you call a single row of the geometry column, it'll return a small plot with the shape. Try other row numbers.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vm9TKjKofOG"
      },
      "outputs": [],
      "source": [
        "gemeenten.loc[17, 'geometry']\n",
        "\n",
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VowZ3tROofOG"
      },
      "source": [
        "# 7.2 Data mapping\n",
        "\n",
        "A choropleth for categorical variables simply assigns a different color to every potential value in the series. The main requirement in this case is then for the color scheme to reflect the fact that different values are not ordered or follow a particular scale.\n",
        "\n",
        "We can create categorical choropleths with geopandas. The following code displays each polygon as whether it is a polygon representing land, water with a legend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPQHcZCkofOH"
      },
      "outputs": [],
      "source": [
        "display(gemeenten.head())\n",
        "\n",
        "gemeenten.plot(column='H2O', cmap='jet', categorical=True, legend=True, legend_kwds={'loc': 'upper left'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79hPJwvvTTq"
      },
      "source": [
        "Remove all the polygons representing water and find the number of municipalities in 2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzmKLaCvtL2t"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Your code goes here\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNu2yhC4ofOI"
      },
      "source": [
        "We can create a map that displays the polygons with colors assigned by some feature values. The following code calculates the area of each polygon. These values can be assigned a color specified by the selected colormap.  Then a new geopandas column called 'area' is created and assigned the area information.  You will see that smaller polygons have lower size and vice versa.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwpVeaUkofOJ"
      },
      "outputs": [],
      "source": [
        "gemeenten.loc[:, 'area'] = gemeenten.geometry.area / 100000\n",
        "gemeenten.plot(figsize=(9, 9), column='area', cmap='jet', legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKYoRliEofOJ"
      },
      "source": [
        "# 7.3 Quantiles\n",
        "One solution to obtain a more balanced classification scheme is using quantiles. This, by definition, assigns the same amount of values to each bin: the entire series is laid out in order and break points are assigned in a way that leaves exactly the same amount of observations between each of them. This \"observation-based\" approach contrasts with the \"value-based\" method of equal intervals and, although it can obscure the magnitude of extreme values, it can be more informative in cases with skewed distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvE4oLaWofOK"
      },
      "outputs": [],
      "source": [
        "gemeenten.plot(figsize=(9, 9), column='area', scheme='QUANTILES', k=3, cmap='jet', legend=True, legend_kwds={'loc': 'upper left'})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}